## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
##

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.storageClass Global StorageClass for Persistent Volume(s)
##
global:
  imageRegistry: ""
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  storageClass: ""

## @section Common parameters
##

## @param nameOverride String to partially override nginx.fullname template (will maintain the release name)
##
nameOverride: ""
## @param fullnameOverride String to fully override nginx.fullname template
##
fullnameOverride: ""
## @param namespaceOverride String to fully override common.names.namespace
##
namespaceOverride: ""
## @param kubeVersion Force target Kubernetes version (using Helm capabilities if not set)
##
kubeVersion: ""
## @param clusterDomain Kubernetes Cluster Domain
##
clusterDomain: cluster.local
## @param extraDeploy Extra objects to deploy (value evaluated as a template)
##
extraDeploy: []
## @param commonLabels Add labels to all the deployed resources
##
commonLabels: {}
## @param commonAnnotations Add annotations to all the deployed resources
##
commonAnnotations: {}

## Enable diagnostic mode in the deployment(s)/statefulset(s)
##
diagnosticMode:
  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
  ##
  enabled: false
  ## @param diagnosticMode.command Command to override all containers in the the deployment(s)/statefulset(s)
  ##
  command:
    - sleep
  ## @param diagnosticMode.args Args to override all containers in the the deployment(s)/statefulset(s)
  ##
  args:
    - infinity

## Deployment or Statefulset
statefulset:
  enabled: false

## @param replicaCount Number of replicas to deploy
##
replicaCount: 1

## @section Nginx parameters
## Bitnami Nginx image version
## ref: https://hub.docker.com/r/bitnami/nginx/tags/
## @param image.registry Nginx image registry
## @param image.repository Nginx image repository
## @param image.tag Nginx image tag (immutable tags are recommended)
## @param image.digest Nginx image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
## @param image.pullPolicy Nginx image pull policy
## @param image.pullSecrets Specify docker-registry secret names as an array
## @param image.debug Specify if debug logs should be enabled
##
image:
  registry: docker.io
  repository: bitnami/nginx
  tag: latest
  digest: ""
  ## Specify a imagePullPolicy
  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
  ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  ##
  pullPolicy: IfNotPresent
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ## Example:
  ## pullSecrets:
  ##   - myRegistryKeySecretName
  ##
  pullSecrets: []

## Kubernetes svc configuration
##
service:
  ## 支持ClusterIP修改为LoadBalancer，反之不允许。可手动修改svc,并将nodePort去掉
  type: ClusterIP # 一般不用修改, 支持ClusterIP/LoadBalancer/NodePort
  loadBalancerIP: ""
  ## Enable client source IP preservation
  ## @param service.externalTrafficPolicy External traffic policy, configure to Local to preserve client source IP when using an external loadBalancer
  ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
  ##
  externalTrafficPolicy: Cluster # 支持Cluster/Local
  ports:
    ## 多端口暴露时，复制一段
    http:
      port: 8080 # Service port number for client-a port.
      protocol: TCP # Service port protocol for client-a port.
      ## appProtocol 用于声明后端应用层协议，告诉 Gateway 后端使用什么协议
      ## ⚠️ 注意：对于 Envoy Gateway，Service 的 appProtocol 可能不起作用
      ## 如果遇到 HTTP/2 协议错误，建议使用 gateway.backend 资源明确声明
      ## kubernetes.io/h1c = HTTP/1.1, gateway.envoyproxy.io/h2c = HTTP/2
      # appProtocol: kubernetes.io/h1c
      ## Use nodePorts to requets some specific ports when usin NodePort
      # nodePort: 30020  # <to set explicitly, choose port between 30000-32767> 默认会自动生成
  ## @param service.loadBalancerSourceRanges Addresses that are allowed when service is LoadBalancer
  ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
  ## e.g:
  ## loadBalancerSourceRanges:
  ## - 10.10.10.0/24
  ##
  loadBalancerSourceRanges: []
  ## @param service.clusterIP Static clusterIP or None for headless services
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#choosing-your-own-ip-address
  ## e.g:
  ## clusterIP: None
  ##
  clusterIP: ""
  ## @param service.annotations Annotations for Logstash service
  ## @param service.sessionAffinity Session Affinity for Kubernetes service, can be "None" or "ClientIP"
  ## If "ClientIP", consecutive client requests will be directed to the same Pod
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies
  ##
  sessionAffinity: None
  ## @param service.sessionAffinityConfig Additional settings for the sessionAffinity
  ## sessionAffinityConfig:
  ##   clientIP:
  ##     timeoutSeconds: 300
  ##
  sessionAffinityConfig: {}
  ## @param service.annotations Service annotations
  ## This can be used to set the LoadBalancer service type to internal only.
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
  ##
  annotations: {}

## @param extraEnvVars Extra environment variables to be set on MinIO&reg; container
## e.g:
## extraEnvVars:
##   - name: FOO
##     value: "bar"
##
extraEnvVars: []
## @param extraEnvVarsCM Name of existing ConfigMap containing extra environment variables
##
extraEnvVarsCM: ""
## @param extraEnvVarsSecret Name of existing Secret containing extra environment variables
##
extraEnvVarsSecret: ""
## @param command Default container command (useful when using custom images). Use array form
##
command: []
## @param args Default container args (useful when using custom images). Use array form
##
args: []

## @param querier.podManagementPolicy podManagementPolicy to manage scaling operation
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
##
podManagementPolicy: ""

## Enable configmap and add data in configmap
config:
  enabled: false
  mountPath: /conf
  subPath: ""
  readOnly: true
  data: {}

## 使用已存在的configmap映射到相应目录或文件路径
existConfig:
  enabled: false
  name: ""
  mountPath: /exist/conf
  subPath: ""
  readOnly: true

## To use an additional secret, set enable to true and add data
secret:
  enabled: false
  mountPath: /etc/secret-volume
  subPath: ""
  readOnly: true
  data: {}

## 使用已存在的secret映射到相应目录或文件路径
existSecret:
  enabled: false
  name: ""
  mountPath: /exist/secret-volume
  subPath: ""
  readOnly: true

## @param customLivenessProbe override default liveness probe
##
customLivenessProbe: {}
## @param customReadinessProbe override default readiness probe
##
customReadinessProbe: {}
## @param customStartupProbe overrides the default one
##
customStartupProbe: {}

## liveness and readiness
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
healthCheck:
  type: tcp # http/tcp
  port: http # 上面的端口名或端口
  httpPath: "/" # http时必须设置
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10 # 初始延迟秒数, k8s默认值为0，最小为0
    periodSeconds: 20 # 检测周期，k8s默认值10，最小为1
    # timeoutSeconds: 3  # 检测超时，k8s默认值1，最小为1
    # successThreshold: 1  # 失败后成功次数，k8s默认值1，最小为1，只能设置为1
    # failureThreshold: 5  # 失败后重试次数，k8s默认值3，最小为1
  readinessProbe:
    enabled: true
    initialDelaySeconds: 10 # 初始延迟秒数, k8s默认值为0，最小为0
    periodSeconds: 20 # 检测周期，k8s默认值10，最小为1
    # timeoutSeconds: 3  # 检测超时，k8s默认值1，最小为1
    # successThreshold: 1  # 失败后成功次数，k8s默认值1，最小为1，只能设置为1
    # failureThreshold: 5  # 失败后重试次数，k8s默认值3，最小为1
  startupProbe:
    enabled: false
    initialDelaySeconds: 60
    periodSeconds: 10
    # timeoutSeconds: 1
    # failureThreshold: 15
    # successThreshold: 1

## @param updateStrategy.type mod-chart deployment strategy type
## @param updateStrategy.rollingUpdate mod-chart deployment rolling update configuration parameters
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
##
updateStrategy: {}
#  type: RollingUpdate
#  rollingUpdate: {}
## @param podLabels Additional labels for mod-chart pods
## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
##
podLabels: {}
## @param podAnnotations Annotations for mod-chart pods
## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
##
podAnnotations: {}
## @param podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
##
podAffinityPreset: ""
## @param podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
##
podAntiAffinityPreset: soft
## Node affinity preset
## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
##
nodeAffinityPreset:
  ## @param nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ##
  type: ""
  ## @param nodeAffinityPreset.key Node label key to match Ignored if `affinity` is set.
  ## E.g.
  ## key: "kubernetes.io/e2e-az-name"
  ##
  key: ""
  ## @param nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set.
  ## E.g.
  ## values:
  ##   - e2e-az1
  ##   - e2e-az2
  ##
  values: []
## @param affinity Affinity for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set
##
affinity: {}
## @param hostNetwork Specify if host network should be enabled for mod-chart pod
##
hostNetwork: false
## @param hostIPC Specify if host IPC should be enabled for mod-chart pod
##
hostIPC: false
## @param nodeSelector Node labels for pod assignment. Evaluated as a template.
## Ref: https://kubernetes.io/docs/user-guide/node-selection/
##
nodeSelector: {}
## @param tolerations Tolerations for pod assignment. Evaluated as a template.
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: []
## @param priorityClassName Priority class name
## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass
##
priorityClassName: ""
## @param schedulerName Name of the k8s scheduler (other than default)
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
schedulerName: ""
## @param terminationGracePeriodSeconds In seconds, time the given to the NGINX pod needs to terminate gracefully
## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
##
terminationGracePeriodSeconds: ""
## @param topologySpreadConstraints Topology Spread Constraints for pod assignment
## https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
## The value is evaluated as a template
##
topologySpreadConstraints: []
## NGINX pods' Security Context.
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
## @param podSecurityContext.enabled Enabled mod-chart pods' Security Context
## @param podSecurityContext.fsGroup Set mod-chart pod's Security Context fsGroup
## @param podSecurityContext.sysctls sysctl settings of the mod-chart pods
##
podSecurityContext:
  enabled: false
  fsGroup: 1001
  ## sysctl settings
  ## Example:
  ## sysctls:
  ## - name: net.core.somaxconn
  ##   value: "10000"
  ##
  sysctls: []
## mod-chart containers' Security Context.
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
## @param containerSecurityContext.enabled Enabled mod-chart containers' Security Context
## @param containerSecurityContext.runAsUser Set mod-chart container's Security Context runAsUser
## @param containerSecurityContext.runAsNonRoot Set mod-chart container's Security Context runAsNonRoot
##
containerSecurityContext:
  enabled: false
  runAsUser: 1001
  runAsNonRoot: true
  # readOnlyRootFilesystem: true
  # allowPrivilegeEscalation: false

## @param Pod's DNS Policy
## https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy
dnsPolicy: "" # ClusterFirst/ClusterFirstWithHostNet ...

## @param hostAliases Deployment pod host aliases
## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
##
hostAliases: []
# - ip: "192.168.1.100"
#   hostnames:
#   - "example.local"

## mod-chart containers' resource requests and limits
## ref: https://kubernetes.io/docs/user-guide/compute-resources/
## We usually recommend not to specify default resources and to leave this as a conscious
## choice for the user. This also increases chances charts run on environments with little
## resources, such as Minikube. If you do want to specify resources, uncomment the following
## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
## @param resources.limits The resources limits for the mod-chart container
## @param resources.requests The requested resources for the mod-chart container
resources:
  ## Example:
  ## limits:
  ##    cpu: 100m
  ##    memory: 128Mi
  limits: {}
  ## Examples:
  ## requests:
  ##    cpu: 100m
  ##    memory: 128Mi
  requests: {}
## NGINX containers' lifecycleHooks
## ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/
## If you do want to specify lifecycleHooks, uncomment the following
## lines, adjust them as necessary, and remove the curly braces on 'lifecycle:{}'.
## @param lifecycleHooks Optional lifecycleHooks for the NGINX container
lifecycleHooks: {}
  ## Example:
  ## postStart:
  ##   exec:
  ##     command: ["/bin/sh", "-c", "echo Hello from the postStart handler > /usr/share/message"]
  ## Example:
  ## preStop:
  ##   exec:
  ##     command: ["/bin/sleep", "20"]
  ##     command: ["/bin/sh","-c","nginx -s quit; while killall -0 nginx; do sleep 1; done"]

## @section Autoscaling
## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
##
autoscaling:
  vpa:
    ## @param autoscaling.vpa.enabled Enable VPA
    ##
    enabled: false
    ## @param autoscaling.vpa.annotations Annotations for VPA resource
    ##
    annotations: {}
    ## @param autoscaling.vpa.controlledResources VPA List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory
    ##
    controlledResources: []
    ## @param autoscaling.vpa.maxAllowed VPA Max allowed resources for the pod
    ## cpu: 200m
    ## memory: 100Mi
    maxAllowed: {}
    ## @param autoscaling.vpa.minAllowed VPA Min allowed resources for the pod
    ## cpu: 200m
    ## memory: 100Mi
    minAllowed: {}
    ## @section VPA update policy
    ##
    updatePolicy:
      ## @param autoscaling.vpa.updatePolicy.updateMode Autoscaling update policy Specifies whether recommended updates are applied when a Pod is started and whether recommended updates are applied during the life of a Pod
      ## Possible values are "Off", "Initial", "Recreate", and "Auto".
      ##
      updateMode: Auto
  hpa:
    ## @param autoscaling.hpa.enabled Enable HPA
    ##
    enabled: false
    ## @param autoscaling.hpa.minReplicas Minimum number of replicas
    ##
    minReplicas: ""
    ## @param autoscaling.hpa.maxReplicas Maximum number of replicas
    ##
    maxReplicas: ""
    ## @param autoscaling.hpa.targetCPU Target CPU utilization percentage
    ##
    targetCPU: ""
    ## @param autoscaling.hpa.targetMemory Target Memory utilization percentage
    ##
    targetMemory: ""

## Enable persistence using Persistent Volume Claims
## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  ## @param persistence.enabled Enable persistence using Persistent Volume Claims
  ##
  enabled: false
  ## @param persistence.existingClaim Name of an existing PVC to use
  ##
  existingClaim: ""
  mountPaths:
    - name: data-storage
      mountPath: /app/data
  # - name: data-storage
  #   mountPath: /config
  #   subPath: config
  # - name: data-storage
  #   mountPath: /data
  #   subPath: data
  ## @param persistence.storageClass Storage class of backing PVC
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: ""
  ## @param persistence.labels Persistent Volume Claim labels
  ##
  labels: {}
  ## @param persistence.annotations Persistent Volume Claim annotations
  ##
  annotations: {}
  ## @param persistence.accessModes Persistent Volume Access Modes
  ##
  accessModes:
    - ReadWriteOnce
  ## @param persistence.size Size of data volume
  ##
  size: 8Gi
  ## @param persistence.selector Selector to match an existing Persistent Volume for ClickHouse data PVC
  ## If set, the PVC can't have a PV dynamically provisioned for it
  ## E.g.
  ## selector:
  ##   matchLabels:
  ##     app: my-app
  ##
  selector: {}
  ## @param persistence.dataSource Custom PVC data source
  ##
  dataSource: {}

## @param extraVolumeMounts Array to add extra mount
##
extraVolumeMounts: []
# - mountPath: /logs
#   name: logs
## @param extraVolumes Array to add extra volumes
##
extraVolumes: []
# - hostPath:
#     path: /home/logs
#   name: logs

## Configure Gateway API resources (HTTPRoute, GRPCRoute, TCPRoute, TLSRoute)
## Gateway API is the next-generation Kubernetes ingress management standard
## ref: https://gateway-api.sigs.k8s.io/
##
## IMPORTANT: You must first create a Gateway resource in your cluster
##
## TLS处理说明:
## 1. TLS Termination (TLS终止) - 推荐，类似Ingress的方式
##    - Gateway处理HTTPS，应用只需提供HTTP服务
##    - 证书配置在Gateway的listener中
##    - HTTPRoute连接到HTTPS listener，应用无需支持HTTPS
## 2. TLS Passthrough (TLS透传) - 应用处理HTTPS
##    - Gateway不解密，直接转发加密流量到应用
##    - 使用TLSRoute而非HTTPRoute
##    - 应用必须自己处理TLS
##
## Example 1: HTTP Gateway (no TLS)
## apiVersion: gateway.networking.k8s.io/v1
## kind: Gateway
## metadata:
##   name: my-gateway
##   namespace: default
## spec:
##   gatewayClassName: eg
##   listeners:
##     - name: http
##       protocol: HTTP
##       port: 80
##
## Example 2: HTTPS Gateway with TLS Termination (类似Ingress)
## apiVersion: gateway.networking.k8s.io/v1
## kind: Gateway
## metadata:
##   name: my-gateway
##   namespace: default
## spec:
##   gatewayClassName: eg
##   listeners:
##     - name: https
##       protocol: HTTPS      # Gateway处理HTTPS
##       port: 443
##       tls:
##         mode: Terminate    # TLS终止，Gateway解密后转发HTTP到应用
##         certificateRefs:
##           - name: my-tls-secret  # TLS证书Secret
##       allowedRoutes:
##         namespaces:
##           from: All
##
gateway:
  ## @param gateway.enabled Enable Gateway API support
  ##
  enabled: false
  ## @param gateway.name Name of the Gateway resource to attach to (used in parentRefs)
  ## This should reference an existing Gateway resource name (e.g., "shared-gateway")
  ## Multiple HTTPRoute/GRPCRoute can share the same Gateway to reuse the LoadBalancer IP
  ## ref: https://gateway-api.sigs.k8s.io/concepts/api-overview/#gateway
  ## Note: This is the Gateway NAME, not the GatewayClass name
  ##
  name: ""
  ## @param gateway.namespace Namespace of the Gateway (if different from release namespace)
  ## Required if the Gateway is in a different namespace (e.g., "envoy-gateway-system")
  ##
  namespace: ""
  ## @param gateway.sectionName Section name of the Gateway listener (optional)
  ## Used when a Gateway has multiple listeners and you want to attach to a specific one
  ## For example: "http" or "https" to attach to a specific listener
  ##
  sectionName: ""

  ## HTTPRoute configuration - Routes HTTP/HTTPS traffic to your service
  ## ref: https://gateway-api.sigs.k8s.io/references/spec/#gateway.networking.k8s.io/v1.HTTPRoute
  ##
  ## 说明: HTTPRoute用于路由HTTP/HTTPS流量
  ## - 当Gateway listener配置为HTTPS(TLS Termination)时，Gateway处理TLS，应用只需HTTP
  ## - 当Gateway listener配置为HTTP时，全程HTTP
  ## - HTTPRoute只需配置路由规则，不需要配置TLS证书（证书在Gateway中配置）
  ##
  ## 配置方式: 完全兼容原生 Gateway API HTTPRoute spec.rules 字段
  ## - 支持所有 Gateway API 原生字段（matches, filters, backendRefs, timeouts 等）
  ## - 自动处理 backendRefs 中的空 name（填充为当前 service）和空 port（使用 service.ports.http.port）
  ## - 你可以直接复制 Gateway API 文档中的 rules 配置，无需修改
  ##
  http:
    ## @param gateway.http.enabled Enable HTTPRoute for HTTP/HTTPS traffic
    ##
    enabled: false
    ## @param gateway.http.annotations Additional annotations for the HTTPRoute resource
    ##
    annotations: {}
    ## @param gateway.http.hostnames List of hostnames to match (SNI for HTTPS, Host header for HTTP)
    ## Example:
    ## hostnames:
    ##   - example.com
    ##   - api.example.com
    ##   - "*.example.com"  # Wildcard support
    ##
    hostnames: []
    ## @param gateway.http.rules HTTPRoute routing rules
    ## Each rule defines match conditions and backend services
    ##
    ## Simple example (default):
    ## rules:
    ##   - matches:
    ##       - path:
    ##           type: PathPrefix     # PathPrefix, Exact, or RegularExpression
    ##           value: /             # Match all paths
    ##     backendRefs:
    ##       - name: ""               # Empty means current release's service name
    ##         port: 80               # Service port to route to
    ##
    ## Advanced example with multiple features:
    ## rules:
    ##   # Rule 1: API v1 routing with header matching
    ##   - matches:
    ##       - path:
    ##           type: PathPrefix
    ##           value: /api/v1
    ##         headers:                # Optional: match specific headers
    ##           - type: Exact
    ##             name: X-API-Version
    ##             value: "1.0"
    ##         queryParams:            # Optional: match query parameters
    ##           - type: Exact
    ##             name: env
    ##             value: production
    ##         method: GET             # Optional: match HTTP method
    ##     filters:                    # Optional: modify request/response
    ##       - type: RequestHeaderModifier
    ##         requestHeaderModifier:
    ##           set:                  # Set/override headers
    ##             - name: X-Backend
    ##               value: v1
    ##           add:                  # Add headers if not exists
    ##             - name: X-Request-Id
    ##               value: "{{.Request.ID}}"
    ##           remove:               # Remove headers
    ##             - X-Debug
    ##       - type: URLRewrite        # Rewrite URL before sending to backend
    ##         urlRewrite:
    ##           hostname: backend.internal.example.com
    ##           path:
    ##             type: ReplacePrefixMatch
    ##             replacePrefixMatch: /v1
    ##     timeouts:                   # Optional: configure timeouts
    ##       request: 30s              # Overall request timeout
    ##       backendRequest: 10s       # Backend request timeout
    ##     backendRefs:
    ##       - name: ""                # Empty = current service, or specify service name
    ##         port: 8080
    ##
    ##   # Rule 2: Canary deployment with traffic weight
    ##   - matches:
    ##       - path:
    ##           type: PathPrefix
    ##           value: /app
    ##     backendRefs:
    ##       - name: ""                # Main version gets 90% traffic
    ##         port: 80
    ##         weight: 90
    ##       - name: myapp-canary      # Canary version gets 10% traffic
    ##         port: 80
    ##         weight: 10
    ##
    ##   # Rule 3: Redirect HTTP to HTTPS
    ##   - matches:
    ##       - path:
    ##           type: PathPrefix
    ##           value: /
    ##     filters:
    ##       - type: RequestRedirect
    ##         requestRedirect:
    ##           scheme: https
    ##           port: 443
    ##           statusCode: 301       # 301 (permanent) or 302 (temporary)
    ##
    ##   # Rule 4: Traffic mirroring for testing
    ##   - matches:
    ##       - path:
    ##           type: PathPrefix
    ##           value: /test
    ##     filters:
    ##       - type: RequestMirror     # Send copy of traffic to test service
    ##         requestMirror:
    ##           backendRef:
    ##             name: test-service
    ##             namespace: testing
    ##             port: 8080
    ##     backendRefs:
    ##       - name: ""
    ##         port: 80
    ##
    rules:
      - matches:
          - path:
              type: PathPrefix
              value: /
        backendRefs:
          - name: ""  # Empty string means: use the current release's service name (auto-filled by template)
            # port: 80  # 如果不指定,默认使用上面service.ports中定义的端口;如果指定,则会覆盖上面的端口配置

  ## BackendTrafficPolicy configuration - Controls traffic from Gateway to backend
  ## ref: https://gateway.envoyproxy.io/latest/api/extension_types/#backendtrafficpolicy
  ##
  ## 说明: BackendTrafficPolicy 用于配置负载均衡、超时、重试、健康检查等高级流量策略
  ## - 注意: BackendTrafficPolicy 必须 attach 到 HTTPRoute/GRPCRoute，不能直接 attach 到 Service
  ## - 协议配置: 推荐使用 Service 的 appProtocol 字段声明后端协议，而不是 useClientProtocol
  ## - 默认不启用，只在需要高级流量控制时启用
  ##
  ## 配置方式: 完全兼容原生 BackendTrafficPolicy API spec 字段
  ## - 推荐使用 spec 字段完全自定义配置
  ## - 也支持分散字段配置（loadBalancer/timeout/http 等）向后兼容
  ##
  backendTrafficPolicy:
    ## @param gateway.backendTrafficPolicy.enabled Enable BackendTrafficPolicy
    ##
    enabled: false
    ## @param gateway.backendTrafficPolicy.annotations Additional annotations for the BackendTrafficPolicy resource
    ##
    annotations: {}
    ## @param gateway.backendTrafficPolicy.spec Complete BackendTrafficPolicy spec (recommended)
    ## 支持所有 BackendTrafficPolicy API 字段: targetRefs, loadBalancer, timeout,
    ## retry, healthCheck, circuitBreaker, proxyProtocol, tcpKeepalive, connection,
    ## http2, dns, useClientProtocol, faultInjection, rateLimit 等
    ##
    ## Example:
    ## spec:
    ##   targetRefs:
    ##     - group: gateway.networking.k8s.io
    ##       kind: HTTPRoute
    ##       name: my-httproute
    ##   loadBalancer:
    ##     type: RoundRobin
    ##   timeout:
    ##     tcp:
    ##       connectTimeout: 10s
    ##     http:
    ##       requestTimeout: 60s
    ##   http:
    ##     http2:
    ##       disabled: true  # 禁用到后端的 HTTP/2，解决 ERR_HTTP2_PROTOCOL_ERROR
    ##   retry:
    ##     numRetries: 2
    ##     retryOn:
    ##       httpStatusCodes: [503]
    ##
    spec: {}
    ## @param gateway.backendTrafficPolicy.targetRefs (Optional) Target references
    ## 留空时自动指向当前的 HTTPRoute 或 GRPCRoute
    ## 如果需要自定义 targetRefs，可以在此配置或使用 spec.targetRefs
    ##
    targetRefs: []
    ## @param gateway.backendTrafficPolicy.loadBalancer (Deprecated) Load balancing - 推荐使用 spec.loadBalancer
    ##
    loadBalancer: {}
      # type: RoundRobin  # RoundRobin, LeastRequest, Random, ConsistentHash
    ## @param gateway.backendTrafficPolicy.timeout (Deprecated) Timeout - 推荐使用 spec.timeout
    ##
    timeout: {}
      # tcp:
      #   connectTimeout: 10s
      # http:
      #   requestTimeout: 60s
    ## @param gateway.backendTrafficPolicy.http (Deprecated) HTTP protocol - 推荐使用 spec.http
    ## 用于解决 ERR_HTTP2_PROTOCOL_ERROR 问题
    ## 当后端服务（如 nginx）不支持 HTTP/2 时，需要禁用到后端的 HTTP/2
    ##
    http: {}
      # http2:
      #   disabled: true  # 禁用到后端的 HTTP/2，强制使用 HTTP/1.1
    ## @param gateway.backendTrafficPolicy.retry (Deprecated) Retry - 推荐使用 spec.retry
    ##
    retry: {}
      # numRetries: 2
      # perRetry:
      #   timeout: 250ms
      # retryOn:
      #   httpStatusCodes:
      #     - 503
    ## @param gateway.backendTrafficPolicy.healthCheck (Deprecated) Health check - 推荐使用 spec.healthCheck
    ##
    healthCheck: {}
      # active:
      #   timeout: 1s
      #   interval: 3s
      #   unhealthyThreshold: 3
      #   healthyThreshold: 1
      #   type: HTTP
      #   http:
      #     path: /health
      #     expectedStatuses:
      #       - start: 200
      #         end: 300
    ## @param gateway.backendTrafficPolicy.circuitBreaker (Deprecated) Circuit breaker - 推荐使用 spec.circuitBreaker
    ##
    circuitBreaker: {}
      # maxConnections: 1024
      # maxPendingRequests: 1024
      # maxParallelRequests: 1024

  ## Backend configuration - Declares backend endpoint protocol (Envoy Gateway extension)
  ## ref: https://gateway.envoyproxy.io/latest/api/extension_types/#backend
  ##
  ## 说明: Backend CRD 用于明确声明后端服务的协议和端点
  ## - Envoy Gateway 默认使用 HTTP/2 连接后端，导致 nginx HTTP/1.1 后端失败
  ## - 通过 Backend 资源声明后端不支持 HTTP/2，强制使用 HTTP/1.1
  ## - 注意: Service 的 appProtocol 对 Envoy Gateway 不起作用！
  ##
  ## 关键：此方案避免修改 Service，完全在 Gateway 层面解决协议问题
  ##
  ## 配置方式: 完全兼容原生 Backend API spec 字段
  ## - 推荐使用 spec 字段完全自定义配置
  ## - 也支持旧的 endpoints/appProtocols 字段配置（向后兼容）
  ##
  backend:
    ## @param gateway.backend.enabled Enable Backend resource (推荐启用以解决 HTTP/2 协议错误)
    ##
    enabled: false
    ## @param gateway.backend.annotations Additional annotations for the Backend resource
    ##
    annotations: {}
    ## @param gateway.backend.spec Complete Backend spec (recommended)
    ## 支持所有 Backend API 字段: endpoints, appProtocols 等
    ##
    ## Example with FQDN endpoint:
    ## spec:
    ##   endpoints:
    ##     - fqdn:
    ##         hostname: myservice.namespace.svc.cluster.local
    ##         port: 80
    ##   appProtocols: []  # 留空使用 HTTP/1.1，或 ["gateway.envoyproxy.io/h2c"] 启用 HTTP/2
    ##
    ## Example with IP endpoint:
    ## spec:
    ##   endpoints:
    ##     - ip:
    ##         address: 10.0.0.1
    ##         port: 80
    ##
    spec: {}
    ## @param gateway.backend.endpoints (Deprecated) Backend endpoints - 向后兼容旧配置
    ## 推荐使用 spec.endpoints 替代
    ##
    endpoints: []
    # - fqdn:
    #     hostname: myservice.namespace.svc.cluster.local
    #     port: 80
    ## @param gateway.backend.appProtocols (Deprecated) Application protocols - 向后兼容旧配置
    ## 推荐使用 spec.appProtocols 替代
    ##
    appProtocols: []

  ## GRPCRoute configuration - Routes gRPC traffic to your service
  ## ref: https://gateway-api.sigs.k8s.io/references/spec/#gateway.networking.k8s.io/v1.GRPCRoute
  ##
  ## 配置方式: 完全兼容原生 Gateway API GRPCRoute spec.rules 字段
  ## - 支持所有原生字段（matches.method, matches.headers, filters, backendRefs 等）
  ## - 自动处理 backendRefs 中的空 name 和 port
  ##
  grpc:
    ## @param gateway.grpc.enabled Enable GRPCRoute for gRPC traffic
    ##
    enabled: false
    ## @param gateway.grpc.annotations Additional annotations for the GRPCRoute resource
    ##
    annotations: {}
    ## @param gateway.grpc.hostnames List of hostnames to match (for gRPC services)
    ## Example:
    ## hostnames:
    ##   - grpc.example.com
    ##
    hostnames: []
    ## @param gateway.grpc.rules GRPCRoute routing rules
    ##
    ## Simple example (default):
    ## rules:
    ##   - backendRefs:
    ##       - name: ""               # Empty means current release's service name
    ##         port: 50051            # gRPC service port
    ##
    ## Advanced example with method matching:
    ## rules:
    ##   # Route specific gRPC method
    ##   - matches:
    ##       - method:
    ##           type: Exact          # Exact or RegularExpression
    ##           service: com.example.UserService    # gRPC service name
    ##           method: GetUser      # gRPC method name
    ##         headers:               # Optional: match gRPC metadata (headers)
    ##           - type: Exact
    ##             name: authorization
    ##             value: "Bearer token"
    ##     filters:
    ##       - type: RequestHeaderModifier
    ##         requestHeaderModifier:
    ##           set:
    ##             - name: x-trace-id
    ##               value: "{{.Request.ID}}"
    ##     backendRefs:
    ##       - name: ""               # Current service
    ##         port: 50051
    ##
    ##   # Route all other gRPC methods to different backend
    ##   - matches:
    ##       - method:
    ##           type: RegularExpression
    ##           service: com.example.UserService
    ##           method: ".*"         # Match all methods
    ##     backendRefs:
    ##       - name: user-service-v2
    ##         port: 50051
    ##
    rules:
      - backendRefs:
          - name: ""  # Empty string means: use the current release's service name (auto-filled by template)
            # port: 50051  # 如果不指定,默认使用上面service.ports中定义的端口;如果指定,则会覆盖上面的端口配置

  ## TCPRoute configuration - Routes raw TCP traffic (databases, message queues, etc.)
  ## ref: https://gateway-api.sigs.k8s.io/references/spec/#gateway.networking.k8s.io/v1alpha2.TCPRoute
  ##
  ## 配置方式: 完全兼容原生 Gateway API TCPRoute spec.rules 字段
  ## - TCPRoute 只支持 backendRefs，不支持 matches（TCP 层无法匹配路径/头部）
  ##
  tcp:
    ## @param gateway.tcp.enabled Enable TCPRoute for TCP traffic
    ##
    enabled: false
    ## @param gateway.tcp.annotations Additional annotations for the TCPRoute resource
    ##
    annotations: {}
    ## @param gateway.tcp.rules TCPRoute routing rules
    ##
    ## TCPRoute is simple - it only routes based on port, no path or header matching
    ##
    ## Example for MySQL:
    ## rules:
    ##   - backendRefs:
    ##       - name: ""               # Current service (MySQL)
    ##         port: 3306
    ##
    ## Example for Redis with traffic weight:
    ## rules:
    ##   - backendRefs:
    ##       - name: redis-p- Routes TLS traffic with SNI matching (TLS passthrough)
  ## Use this when you want the backend to handle TLS termination, not the Gateway
  ## ref: https://gateway-api.sigs.k8s.io/references/spec/#gateway.networking.k8s.io/v1alpha2.TLSRoute
  ##
  tls:
    ## @param gateway.tls.enabled Enable TLSRoute for TLS passthrough
    ##
    enabled: false
    ## @param gateway.tls.annotations Additional annotations for the TLSRoute resource
    ##
    annotations: {}
    ## @param gateway.tls.hostnames List of SNI hostnames to match
    ## TLSRoute matches based on SNI (Server Name Indication) from TLS handshake
    ## Example:
    ## hostnames:
    ##   - secure.example.com
    ##   - "*.secure.example.com"
    ##
    hostnames: []
    ## @param gateway.tls.rules TLSRoute routing rules
    ##
    ## TLSRoute passes encrypted traffic directly to backend (no TLS termination at Gateway)
    ## Backend service must handle TLS termination itself
    ##
    ## Example for HTTPS backend:
    ## rules:
    ##   - backendRefs:
    ##       - name: ""               # Backend service with TLS
    ##         port: 443
    ##
    ## Example with traffic weight:
    ## rules:
    ##   - backendRefs:
    ##       - name: secure-v1
    ##         port: 443
    ##         weight: 70
    ##       - name: secure-v2
    ##         port: 443
    ##         weight: 30
    ##
    rules:
      - backendRefs:
          - name: ""  # Empty string means: use the current release's service name (auto-filled by template)
            # port: 3306  # 如果不指定,默认使用上面service.ports中定义的端口;如果指定,则会覆盖上面的端口配置

  ## TLSRoute configuration - Routes TLS traffic with SNI matching (TLS passthrough)
  ## Use this when you want the backend to handle TLS termination, not the Gateway
  ## ref: https://gateway-api.sigs.k8s.io/references/spec/#gateway.networking.k8s.io/v1alpha2.TLSRoute
  ##
  ## 说明: TLSRoute用于TLS Passthrough场景
  ## - Gateway不解密TLS，直接转发加密流量到应用
  ## - 应用必须自己处理HTTPS和TLS证书
  ## - 如果你习惯Ingress的方式（Gateway处理TLS），应该使用HTTPRoute而非TLSRoute
  ##
  ## 配置方式: 完全兼容原生 Gateway API TLSRoute spec.rules 字段
  ##
  tls:
    ## @param gateway.tls.enabled Enable TLSRoute for TLS passthrough
    ##
    enabled: false
    ## @param gateway.tls.annotations Additional annotations for the TLSRoute resource
    ##
    annotations: {}
    ## @param gateway.tls.hostnames List of SNI hostnames to match
    ## TLSRoute matches based on SNI (Server Name Indication) from TLS handshake
    ## Example:
    ## hostnames:
    ##   - secure.example.com
    ##   - "*.secure.example.com"
    ##
    hostnames: []
    ## @param gateway.tls.rules TLSRoute routing rules
    ##
    ## TLSRoute passes encrypted traffic directly to backend (no TLS termination at Gateway)
    ## Backend service must handle TLS termination itself
    ##
    ## Example for HTTPS backend:
    ## rules:
    ##   - backendRefs:
    ##       - name: ""               # Backend service with TLS
    ##         port: 443
    ##
    ## Example with traffic weight:
    ## rules:
    ##   - backendRefs:
    ##       - name: secure-v1
    ##         port: 443
    ##         weight: 70
    ##       - name: secure-v2
    ##         port: 443
    ##         weight: 30
    ##
    rules:
      - backendRefs:
          - name: ""
            # port: 443  # 如果不指定,默认使用上面service.ports中定义的端口;如果指定,则会覆盖上面的端口配置

## Configure the ingress resource that allows you to access the
## ref: https://kubernetes.io/docs/user-guide/ingress/
##
ingress:
  ## @param ingress.enabled Enable ingress controller resource
  ##
  enabled: false
  ## @param ingress.apiVersion Force Ingress API version (automatically detected if not set)
  ##
  apiVersion: ""
  ## @param ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
  ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster.
  ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
  ##
  ingressClassName: ""
  ## @param ingress.hostname Default host for the ingress resource
  ##
  hostname: chart-example.local
  ## @param ingress.path The Path to mod-chart&reg;. You may need to set this to '/*' in order to use this with ALB ingress controllers.
  ##
  path: /
  ## @param ingress.pathType Ingress path type
  ##
  pathType: ImplementationSpecific
  ## @param ingress.servicePort Service port to be used
  ## Default is http. Alternative is https.
  ##
  servicePort: http
  ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
  ## For a full list of possible ingress annotations, please see
  ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
  ## Use this parameter to set the required annotations for cert-manager, see
  ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
  ##
  ## e.g:
  ## annotations:
  ##   kubernetes.io/ingress.class: nginx
  ##   cert-manager.io/cluster-issuer: cluster-issuer-name
  ##
  annotations: {}
  ## @param ingress.tls Enable TLS configuration for the hostname defined at `ingress.hostname` parameter
  ## TLS certificates will be retrieved from a TLS secret with name: `{{- printf "%s-tls" .Values.ingress.hostname }}`
  ## You can:
  ##   - Use the `ingress.secrets` parameter to create this TLS secret
  ##   - Rely on cert-manager to create it by setting the corresponding annotations
  ##   - Rely on Helm to create self-signed certificates by setting `ingress.selfSigned=true`
  ##
  tls: false
  ## @param ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
  ##
  selfSigned: false
  ## @param ingress.extraHosts The list of additional hostnames to be covered with this ingress record.
  ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array
  ## e.g:
  ## extraHosts:
  ##   - name: chart-example.local
  ##     path: /
  ##
  extraHosts: []
  ## @param ingress.extraPaths Any additional paths that may need to be added to the ingress under the main host
  ## For example: The ALB ingress controller requires a special rule for handling SSL redirection.
  ## extraPaths:
  ## - path: /*
  ##   backend:
  ##     serviceName: ssl-redirect
  ##     servicePort: use-annotation
  ##
  extraPaths: []
  ## @param ingress.extraTls The tls configuration for additional hostnames to be covered with this ingress record.
  ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
  ## e.g:
  ## extraTls:
  ## - hosts:
  ##     - chart-example.local
  ##   secretName: chart-example.local-tls
  ##
  extraTls: []
  ## @param ingress.secrets If you're providing your own certificates, please use this to add the certificates as secrets
  ## key and certificate are expected in PEM format
  ## name should line up with a secretName set further up
  ##
  ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
  ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
  ## It is also possible to create and manage the certificates outside of this helm chart
  ## Please see README.md for more information
  ##
  ## Example
  ## secrets:
  ##   - name: chart-example.local-tls
  ##     key: ""
  ##     certificate: ""
  ##
  secrets: []
  ## @param ingress.extraRules Additional rules to be covered with this ingress record
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules
  ## e.g:
  ## extraRules:
  ## - host: example.local
  ##     http:
  ##       path: /
  ##       backend:
  ##         service:
  ##           name: example-svc
  ##           port:
  ##             name: http
  ##
  extraRules: []

## @section Other Parameters
##

## Network Policy configuration
## ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
##
networkPolicy:
  ## @param networkPolicy.enabled Enable creation of NetworkPolicy resources
  ##
  enabled: false
  ## @param networkPolicy.allowExternal Don't require client label for connections
  ## When set to false, only pods with the correct client label will have network access to the ports
  ## Redis&trade; is listening on. When true, Redis&trade; will accept connections from any source
  ## (with the correct destination port).
  ##
  allowExternal: true
  ## @param networkPolicy.extraIngress Add extra ingress rules to the NetworkPolicy
  ## e.g:
  ##       - port: 1234
  ##     from:
  ##       - podSelector:
  ##           - matchLabels:
  ##               - role: frontend
  ##       - podSelector:
  ##           - matchExpressions:
  ##               - key: role
  ##                 operator: In
  ##                 values:
  ##                   - frontend
  ##
  extraIngress: []
  ## @param networkPolicy.extraEgress Add extra ingress rules to the NetworkPolicy
  ## e.g:
  ## extraEgress:
  ##   - ports:
  ##       - port: 1234
  ##     to:
  ##       - podSelector:
  ##           - matchLabels:
  ##               - role: frontend
  ##       - podSelector:
  ##           - matchExpressions:
  ##               - key: role
  ##                 operator: In
  ##                 values:
  ##                   - frontend
  ##
  extraEgress: []
  ## @param networkPolicy.ingressNSMatchLabels Labels to match to allow traffic from other namespaces
  ## @param networkPolicy.ingressNSPodMatchLabels Pod labels to match to allow traffic from other namespaces
  ##
  ingressNSMatchLabels: {}
  ingressNSPodMatchLabels: {}

## Pods Service Account
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
##
serviceAccount:
  ## @param serviceAccount.create Enable creation of ServiceAccount for nginx pod
  ##
  create: false
  ## @param serviceAccount.name The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the `common.names.fullname` template
  name: ""
  ## @param serviceAccount.annotations Annotations for service account. Evaluated as a template.
  ## Only used if `create` is `true`.
  ##
  annotations: {}
  ## @param serviceAccount.automountServiceAccountToken Auto-mount the service account token in the pod
  ##
  automountServiceAccountToken: false
## @param sidecars Sidecar parameters
## e.g:
## sidecars:
##   - name: your-image-name
##     image: your-image
##     imagePullPolicy: Always
##     ports:
##       - name: portname
##         containerPort: 1234
##
sidecars: []

## @param sidecarSingleProcessNamespace Enable sharing the process namespace with sidecars
## This will switch pod.spec.shareProcessNamespace parameter
##
sidecarSingleProcessNamespace: false

## @param initContainers Extra init containers
##
initContainers: []
## Pod Disruption Budget configuration
## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
##
pdb:
  ## @param pdb.create Created a PodDisruptionBudget
  ##
  create: false
  ## @param pdb.minAvailable Min number of pods that must still be available after the eviction.
  ## You can specify an integer or a percentage by setting the value to a string representation of a percentage (eg. "50%"). It will be disabled if set to 0
  ##
  minAvailable: 1
  ## @param pdb.maxUnavailable Max number of pods that can be unavailable after the eviction.
  ## You can specify an integer or a percentage by setting the value to a string representation of a percentage (eg. "50%"). It will be disabled if set to 0
  ##
  maxUnavailable: 0
## Prometheus Exporter / Metrics
##
metrics:
  ## @param metrics.enabled Start a Prometheus exporter sidecar container
  ##
  enabled: false
  ## @param metrics.port NGINX Container Status Port scraped by Prometheus Exporter
  ## Defaults to specified http port
  port: ""
  ## Bitnami NGINX Prometheus Exporter image
  ## ref: https://hub.docker.com/r/bitnami/nginx-exporter/tags/
  ## @param metrics.image.registry NGINX Prometheus exporter image registry
  ## @param metrics.image.repository NGINX Prometheus exporter image repository
  ## @param metrics.image.tag NGINX Prometheus exporter image tag (immutable tags are recommended)
  ## @param metrics.image.digest NGINX Prometheus exporter image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ## @param metrics.image.pullPolicy NGINX Prometheus exporter image pull policy
  ## @param metrics.image.pullSecrets Specify docker-registry secret names as an array
  ##
  image:
    registry: docker.io
    repository: bitnami/nginx-exporter
    tag: latest
    digest: ""
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## @param metrics.podAnnotations Additional annotations for NGINX Prometheus exporter pod(s)
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  ## @param metrics.securityContext.enabled Enabled NGINX Exporter containers' Security Context
  ## @param metrics.securityContext.runAsUser Set NGINX Exporter container's Security Context runAsUser
  ##
  securityContext:
    enabled: false
    runAsUser: 1001
  ## Prometheus exporter service parameters
  ##
  service:
    ## @param metrics.service.port NGINX Prometheus exporter service port
    ##
    port: 9113
    ## @param metrics.service.annotations [object] Annotations for the Prometheus exporter service
    ##
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "{{ .Values.metrics.service.port }}"
  ## NGINX Prometheus exporter resource requests and limits
  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## @param metrics.resources.limits The resources limits for the NGINX Prometheus exporter container
  ## @param metrics.resources.requests The requested resources for the NGINX Prometheus exporter container
  ##
  resources:
    ## Example:
    ## limits:
    ##    cpu: 100m
    ##    memory: 128Mi
    limits: {}
    ## Examples:
    ## requests:
    ##    cpu: 100m
    ##    memory: 128Mi
    requests: {}
  ## Prometheus Operator ServiceMonitor configuration
  ##
  serviceMonitor:
    ## @param metrics.serviceMonitor.port the service port to scrape metrics from
    ##
    port: http-metrics
    ## @param metrics.serviceMonitor.enabled Create ServiceMonitor resource(s) for scraping metrics using PrometheusOperator
    ##
    enabled: false
    ## @param metrics.serviceMonitor.namespace The namespace in which the ServiceMonitor will be created
    ##
    namespace: ""
    ## @param metrics.serviceMonitor.interval The interval at which metrics should be scraped
    ##
    interval: 30s
    ## @param metrics.serviceMonitor.scrapeTimeout The timeout after which the scrape is ended
    ##
    scrapeTimeout: ""
    ## @param metrics.serviceMonitor.relabelings Metrics RelabelConfigs to apply to samples before scraping.
    ##
    relabelings: []
    ## @skip metrics.serviceMonitor.relabellings DEPRECATED: Use `metrics.serviceMonitor.relabelings` instead.
    ##
    relabellings: []
    ## @param metrics.serviceMonitor.metricRelabelings Metrics RelabelConfigs to apply to samples before ingestion.
    ##
    metricRelabelings: []
    ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint
    ##
    honorLabels: false
    ## @param metrics.serviceMonitor.additionalLabels Additional labels that can be used so ServiceMonitor resource(s) can be discovered by Prometheus
    ##
    additionalLabels: {}
    ## @param metrics.serviceMonitor.podTargetLabels Labels from the Kubernetes pod to be transferred to the created metrics
    ##
    podTargetLabels: []
    ## @param metrics.serviceMonitor.sampleLimit Limit of how many samples should be scraped from every Pod
    ##
    sampleLimit: false
    ## @param metrics.serviceMonitor.targetLimit Limit of how many targets should be scraped
    ##
    targetLimit: false
    ## @param metrics.serviceMonitor.additionalEndpoints  Additional endpoints to scrape (e.g sentinel)
    ##
    additionalEndpoints: []
    # uncomment in order to scrape sentinel metrics, also to in order distinguish between Sentinel and Redis container metrics
    # add metricRelabelings with label like app=redis to main redis pod-monitor port
    # - interval: "30s"
    #   path: "/scrape"
    #   port: "http-metrics"
    #   params:
    #     target: ["localhost:26379"]
    #   metricRelabelings:
    #     - targetLabel: "app"
    #       replacement: "sentinel"
  ## Prometheus Pod Monitor
  ## ref: https://github.com/coreos/prometheus-operator
  ##      https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#podmonitor
  ##
  podMonitor:
    ## @param metrics.podMonitor.port the pod port to scrape metrics from
    ##
    port: metrics
    ## @param metrics.podMonitor.enabled Create PodMonitor resource(s) for scraping metrics using PrometheusOperator
    ##
    enabled: false
    ## @param metrics.podMonitor.namespace The namespace in which the PodMonitor will be created
    ##
    namespace: ""
    ## @param metrics.podMonitor.interval The interval at which metrics should be scraped
    ##
    interval: 30s
    ## @param metrics.podMonitor.scrapeTimeout The timeout after which the scrape is ended
    ##
    scrapeTimeout: ""
    ## @param metrics.podMonitor.relabelings Metrics RelabelConfigs to apply to samples before scraping.
    ##
    relabelings: []
    ## @skip metrics.podMonitor.relabellings DEPRECATED: Use `metrics.podMonitor.relabelings` instead.
    ##
    relabellings: []
    ## @param metrics.podMonitor.metricRelabelings Metrics RelabelConfigs to apply to samples before ingestion.
    ##
    metricRelabelings: []
    # - targetLabel: "app"
    #   replacement: "redis"
    ## @param metrics.podMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint
    ##
    honorLabels: false
    ## @param metrics.podMonitor.additionalLabels Additional labels that can be used so PodMonitor resource(s) can be discovered by Prometheus
    ##
    additionalLabels: {}
    ## @param metrics.podMonitor.podTargetLabels Labels from the Kubernetes pod to be transferred to the created metrics
    ##
    podTargetLabels: []
    ## @param metrics.podMonitor.sampleLimit Limit of how many samples should be scraped from every Pod
    ##
    sampleLimit: false
    ## @param metrics.podMonitor.targetLimit Limit of how many targets should be scraped
    ##
    targetLimit: false
    ## @param metrics.podMonitor.additionalEndpoints  Additional endpoints to scrape (e.g sentinel)
    ##
    additionalEndpoints: []
    # - interval: "30s"
    #   path: "/scrape"
    #   port: "metrics"
    #   params:
    #     target: ["localhost:26379"]
    #   metricRelabelings:
    #     - targetLabel: "app"
    #       replacement: "sentinel"
  ## Prometheus Operator PrometheusRule configuration
  ##
  prometheusRule:
    ## @param metrics.prometheusRule.enabled if `true`, creates a Prometheus Operator PrometheusRule (also requires `metrics.enabled` to be `true` and `metrics.prometheusRule.rules`)
    ##
    enabled: false
    ## @param metrics.prometheusRule.namespace Namespace for the PrometheusRule Resource (defaults to the Release Namespace)
    ##
    namespace: ""
    ## @param metrics.prometheusRule.additionalLabels Additional labels that can be used so PrometheusRule will be discovered by Prometheus
    ##
    additionalLabels: {}
    ## @param metrics.prometheusRule.rules Prometheus Rule definitions
    ##   - alert: LowInstance
    ##     expr: up{service="{{ template "common.names.fullname" . }}"} < 1
    ##     for: 1m
    ##     labels:
    ##       severity: critical
    ##     annotations:
    ##       description: Service {{ template "common.names.fullname" . }} Nginx is down since 1m.
    ##       summary: Nginx instance is down.
    ##
    rules: []
